{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classification\n",
    "\n",
    "### 1.1 Data Transformation\n",
    "\n",
    "In demo 4, we introduced the trace-based method for the tip movement recognition. The images we used in that demo was the scaled ones. Since the range of movement is a very important indicator because it can show whether the movement is sufficient(e.g. insufficient movements result in small circular motions, and sufficient movements result in larger size circular movement), we decide to unscale the movement.\n",
    "\n",
    "Example image:\n",
    "![](https://image.ibb.co/bsBUFn/4h_json7.png)\n",
    "\n",
    "Note that each trace image contains 20 data points.\n",
    "\n",
    "Since we use the y-axis and z-axis as the 2 dimensions of the trace images, we need to find the fixed range for all the images.\n",
    "\n",
    "As for the y-axis, we calculate the difference lr(1), lr(2)...lr(n) of the left-most and right-most point in each trace images, and choose the maximum difference y_range=lr(k) as the fixed range of the y-axis.\n",
    "\n",
    "As for the z-axis, we calculate the difference ub(1), ub(2)...ub(n) of the up-most and bottom-most point in each trace images, and choose the maximum difference z_range=ub(k) as the fixed range of the z-axis.\n",
    "\n",
    "Then we re-plot all the images using y_range and z_range as the width and height of each image.\n",
    "\n",
    "This caused some images to be too small thus reduced the number of usable images from 22000 to 7000. These 7000 images chosen have the range of movements covering 60% of the image width and height.\n",
    "\n",
    "### 1.2 Classification\n",
    "\n",
    "We add layers to the previous Deep Neural Network model CNN. It is now a 16-layers VGG16 CNN model.\n",
    "\n",
    "This gave 83 % precision and 82 % recall for test data of 1a but 1b but did not work well for the new data set 1c indicating overfitting problem again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problem Transformation: Classification to Clustering\n",
    "\n",
    "### 2.1 Hypothesis Created for the LanceMotion Project\n",
    "\n",
    "Back to the beginning of this project, three hypothesis are made to support the development and research:\n",
    "\n",
    "1. The shape and size of movement path has correlation with the tips\n",
    "2. The process data affect size and shape. This relationship is more complex than linear correlation.\n",
    "3. Bad tips have higher probabilities to draw bad shaped path\n",
    "\n",
    "\n",
    "The first hypothesis is based on the requirement analysis of the project. Sometimes human eyes can tell whether it is a good move or not.\n",
    "\n",
    "Hypothesis 3 is based on probabilities, which means bad tips can still have good movements, while good tips can still have bad movements.\n",
    "\n",
    "### 2.2 Two Approaches to Transform the Problem\n",
    "\n",
    "1. Human classifying: human shapes classification based on intuition.Calculate the percentage of each human defined class and analyse the probability distributions.\n",
    "2. Clustering: define the number of clusters and let the clustering algorithms do their work. Calculate the percentage of each cluster and analyse the probability distributions.\n",
    "\n",
    "The feature can be used after getting the result of classification/clustering: [shape, size, process data]. Shape can be probabilities\n",
    "\n",
    "These methods represent how operators evaluate lance movement intuitively. They are intended to simulate the human observation process.\n",
    "\n",
    "According to demo 5 discussion, it is better to use the clustering methods because human eyes can easily make mistakes and clustering can make our life easier by not tagging the data manually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering\n",
    "\n",
    "### 3.1 Clustering Algorithm Choice\n",
    "\n",
    "There are tons of clustering algorithms exists. Each clustering algorithms have their \"killer application\". They can be great for some data type and bad for others. This image shows the comparison between different algorithms:\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_0011.png)\n",
    "\n",
    "(See http://scikit-learn.org/stable/modules/clustering.html for more detail)\n",
    "\n",
    "For most of the tasks, k-means could already be a good choice. After trying for 4 different algorithms, we decide to use k-means for this task. (It can be replaced easily if needed later)\n",
    "\n",
    "### 3.2 Result of the Clustering and the Performance of the Algorithm\n",
    "\n",
    "The input of the algorithm is all the 7000 images introduced in section 1.1. \n",
    "The output result of the algorithm as an array [0,1,3,2,4,5...3,1,5]. Each element in the result array represents the cluster No. the corresponding image belongs to.\n",
    "\n",
    "The performance of the algorithm is pretty good. It takes about 1 min to train the clustering model using the 7000 images with the size of 80x60.\n",
    "    \n",
    "### 3.3 The Result of the Clustered Images\n",
    "\n",
    "After getting the result array, another Python script is written to separate the original images into clusters.\n",
    "\n",
    "# Cluster_folders.bmp\n",
    "\n",
    "Each cluster is in one folder, from 0 to 4.\n",
    "\n",
    "Here are some sample images of each cluster:\n",
    "\n",
    "# cluster0,1,2,3,4.bmp\n",
    "\n",
    "Result Analysis:\n",
    "0: the shape that is smaller than others, \n",
    "1: banana shape, \n",
    "2: feather shape, \n",
    "3: line shape, \n",
    "4: round or random shape. \n",
    "\n",
    "The result shows that the algorithm has the effect that is close to human-made clustering. \n",
    "\n",
    "### 3.4 Clustering VS Type of Tips\n",
    "\n",
    "After getting the result, we use Excel to do the analysis.\n",
    "\n",
    "In the table below, each row represents the information of an experiment trial. The numbers in the column of 'cluster0'-'cluster4' represents the number of images that belong to each cluster.\n",
    "\n",
    "# image of all\n",
    "\n",
    "Then we separate them into good tips and bad tips for further investigation.\n",
    "\n",
    "Good Tips:\n",
    "\n",
    "# image of good\n",
    "\n",
    "Bad Tips:\n",
    "\n",
    "# image of bad\n",
    "\n",
    "The pie charts show the percentage of each cluster and the bar charts show the number of images in each cluster. \n",
    "\n",
    "### 3.5 Conclusions\n",
    "\n",
    "1. Class 2 means good \n",
    "2. Class 0 means bad, \n",
    "3. Other groups are indecisive\n",
    "4. Low number of cluster 3 can also indicate a bad tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
